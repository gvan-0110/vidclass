{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Project Complete.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install required libraries"
      ],
      "metadata": {
        "id": "k7MXn4q5gB05"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFcekeCtzTqQ"
      },
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install opencv-python\n",
        "!pip install tensorflow\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load API's needed for program\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob, os, time, random\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Initialize globally used variables\n",
        "\n",
        "average_frame_size = (144, 256, 3)\n",
        "categories_int = {}\n",
        "int_categories = {}\n",
        "color_model = None\n",
        "content_model = None"
      ],
      "metadata": {
        "id": "eRuKbWKegSCW"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot function to display images for testing\n",
        "def plotImage(image):\n",
        "  plt.figure(figsize = (15,2))\n",
        "  plt.imshow(image)"
      ],
      "metadata": {
        "id": "ZPvqznUxMXW1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load training data from directory"
      ],
      "metadata": {
        "id": "XGoHrR0J_r8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load actual data from file path\n",
        "\n",
        "# Folder structure should be:\n",
        "# Level 1 : names of categories as folder name -> timelapse animation frogs ... etc\n",
        "# Level 2 : name of video as folder name -> frog_in_sun dogs_jumping ... etc\n",
        "# Level 3 : frames as png with sequential numbering as name -> 1 2 3 4 ... 10\n",
        "\n",
        "def loadData(file_path_to_folders):\n",
        "  '''Video data returns a tuple, the first element is the loaded frames\n",
        "    The second element is a list of the categories as strings\n",
        "\n",
        "    The loaded frames data is formatted as a dictionary, values are as follows:\n",
        "    {category_type : [[video1_frames], [video2_frames], ...], category2_type : [...], ...}\n",
        "    video_data[0][\"timelapse\"][2][3] gives the third timelapse video's 4th frame\n",
        "  '''\n",
        "\n",
        "  categories = next(os.walk(file_path_to_folders))[1]\n",
        "  video_categories = {}\n",
        "\n",
        "  for category in categories:\n",
        "    video_categories[category] = []\n",
        "    video_titles = next(os.walk(file_path_to_folders + \"/\" + category))[1]\n",
        "\n",
        "    for video_title in video_titles:\n",
        "      final_path = file_path_to_folders + \"/\" + category + \"/\" + video_title + \"/\"\n",
        "      video_frames = []\n",
        "\n",
        "      for image in sorted(glob.glob(final_path + \"*.png\")):\n",
        "        frame = cv2.imread(image)\n",
        "        if frame.shape != average_frame_size:\n",
        "          frame = cv2.resize(frame, (256, 144))\n",
        "          print(frame.shape , \"\")\n",
        "        video_frames.append(frame)\n",
        "\n",
        "      video_categories[category].append(video_frames)\n",
        "\n",
        "\n",
        "  for index, category in enumerate(categories):\n",
        "    categories_int[category] = index\n",
        "    int_categories[index] = category\n",
        "  return (video_categories, categories)"
      ],
      "metadata": {
        "id": "pJu1uz98-huu"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions used for average color network data formatting"
      ],
      "metadata": {
        "id": "RC1EIvrX7PsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Average all frames selected in video into a single image\n",
        "def averageFrames(frames):\n",
        "  frameAmount = len(frames)\n",
        "  averageFrame = np.zeros(average_frame_size)\n",
        "  for frame in frames:\n",
        "    #print(averageFrame.shape , \" : \" , frame.shape)\n",
        "    averageFrame = averageFrame + frame\n",
        "  averageFrame = averageFrame / frameAmount\n",
        "  return averageFrame\n",
        "\n",
        "# Normalize image for input\n",
        "def normalizeFrame(frame):\n",
        "  return (frame / 255)\n",
        "\n",
        "def get_frames_averaged(frame_data, categories):\n",
        "  average_frames = {}\n",
        "  for category in categories:\n",
        "    average_frames[category] = []\n",
        "    for video in frame_data[category]:\n",
        "      average_frames[category].append(normalizeFrame(averageFrames(video)))\n",
        "  return average_frames"
      ],
      "metadata": {
        "id": "C8XbFZ0n1OUE"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions used for content network data formatting"
      ],
      "metadata": {
        "id": "jRHiNFJtiw7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def differentiateFrames(frames):\n",
        "  frameAmount = len(frames)\n",
        "  newFrames = []\n",
        "  if frameAmount == 1:\n",
        "    return frames\n",
        "  for index, frame in enumerate(frames):\n",
        "    if(index + 1 >= frameAmount):\n",
        "      return newFrames\n",
        "    frameCurrent = frame\n",
        "    frameNext = frames[index + 1]\n",
        "    frameDifference = frameCurrent - frameNext\n",
        "    newFrames.append(normalizeFrame(frameDifference))\n",
        "\n",
        "def get_frames_difference(frame_data, categories):\n",
        "  differentiated_frames = {}\n",
        "  for category in categories:\n",
        "    differentiated_frames[category] = []\n",
        "    for video in frame_data[category]:\n",
        "      differentiated_frames[category].append(differentiateFrames(video))\n",
        "  return differentiated_frames"
      ],
      "metadata": {
        "id": "gHXHQuNJizog"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create models for both networks"
      ],
      "metadata": {
        "id": "4tQuAzV5p2Ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load models as convolutional network with 2 filter layers and 2 pooling layers\n",
        "# The final network is a dense network of 64 neurons with a final output layer of neurons equal to the category list amount\n",
        "def create_network_models():\n",
        "  global color_model\n",
        "  global content_model\n",
        "  \n",
        "  color_model = models.Sequential([\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=average_frame_size),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(len(categories), activation='softmax')\n",
        "  ])\n",
        "\n",
        "  content_model = models.Sequential([\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=average_frame_size),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(len(categories), activation='softmax')\n",
        "  ])\n",
        "\n",
        "  color_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  content_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "T2zIPeUzlUJa"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Format data information into model usable variables"
      ],
      "metadata": {
        "id": "v8n9QGBc_44s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# format data for color model in x and y dimensions\n",
        "def format_color_data(average_frames):\n",
        "  x_color_train = []\n",
        "  y_color_train = []\n",
        "  x_color_test = []\n",
        "  y_color_test = []\n",
        "\n",
        "  for category in categories_int.keys():\n",
        "    for frame in average_frames[category]:\n",
        "      x_color_train.append(frame)\n",
        "      y_color_train.append(categories_int[category])\n",
        "\n",
        "  return (np.asarray(x_color_train), np.asarray(y_color_train), np.asarray(x_color_test), np.asarray(y_color_test))"
      ],
      "metadata": {
        "id": "vthQsQMEr1Cm"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# format data for content model in x and y dimensions\n",
        "def format_content_data(differentiated_frames):\n",
        "  x_content_train = []\n",
        "  y_content_train = []\n",
        "  x_content_test = []\n",
        "  y_content_test = []\n",
        "\n",
        "  for category in categories_int.keys():\n",
        "    for video in differentiated_frames[category]:\n",
        "      for frame in video:\n",
        "        x_content_train.append(frame)\n",
        "        y_content_train.append(categories_int[category])\n",
        "\n",
        "  return (np.asarray(x_content_train), np.asarray(y_content_train), np.asarray(x_content_test), np.asarray(y_content_test))"
      ],
      "metadata": {
        "id": "wS_-m_YAsD_r"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train models and get accuracy"
      ],
      "metadata": {
        "id": "iGJyfs2oABtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_color_model(x_color_train, y_color_train, epoch_count):\n",
        "  color_model.fit(x_color_train, y_color_train, epochs=epoch_count)"
      ],
      "metadata": {
        "id": "l7tHmVNNpBKW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_content_model(x_content_train, y_content_train, epoch_count):\n",
        "  content_model.fit(x_content_train, y_content_train, epochs=epoch_count)"
      ],
      "metadata": {
        "id": "-aM4qKR-wZze"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load testing video"
      ],
      "metadata": {
        "id": "3fk0BPWMz1PW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video = []\n",
        "\n",
        "def get_video_from_path(path_to_video):\n",
        "  vidmp4 = cv2.VideoCapture(path_to_video)\n",
        "  return vidmp4\n",
        "\n",
        "def get_split_video_frames(video, amount, category):\n",
        "  video_frames = {}\n",
        "  for category_type in categories:\n",
        "    video_frames[category_type] = []\n",
        "  video_frames[category].append([])\n",
        "\n",
        "  data_path = \".\" + \"/testingimage\"\n",
        "  if os.path.exists(data_path):\n",
        "    shutil.rmtree(data_path)\n",
        "  os.mkdir(data_path)\n",
        "\n",
        "  iteration = int((video.get(cv2.CAP_PROP_FRAME_COUNT) - 150) / amount)\n",
        "  success,image = video.read()\n",
        "  count = 0\n",
        "  frame_count = 0\n",
        "  while success:\n",
        "    if (count % iteration) == 0:\n",
        "      frame = image\n",
        "      if frame.shape != average_frame_size:\n",
        "          frame = cv2.resize(frame, (144, 256))\n",
        "      cv2.imwrite(data_path + \"/\" + str(frame_count) + \".png\", frame)\n",
        "      read_frame = cv2.imread(data_path + \"/\" + str(frame_count) + \".png\")\n",
        "      video_frames[category][0].append(read_frame)\n",
        "      frame_count = frame_count + 1\n",
        "    success,image = video.read()\n",
        "    count += 1\n",
        "    return video_frames"
      ],
      "metadata": {
        "id": "_IY-tjjRz4ha"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict a video category from video data"
      ],
      "metadata": {
        "id": "FG7VlRZrKasw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_video_type(color_data, content_data):\n",
        "  color_pred = color_model.predict(color_data[0])\n",
        "\n",
        "  predicted_color_category = [np.argmax(element) for element in color_pred][0]\n",
        "  print(\"Color prediction : \" + str(predicted_color_category))\n",
        "\n",
        "  content_pred = content_model.predict(content_data[0])\n",
        "\n",
        "  predicted_content_category = [np.argmax(element) for element in content_pred]\n",
        "  avg_content_pred = round((np.sum(predicted_content_category)) / len(predicted_content_category))\n",
        "  print(\"Content prediction : \" + str(avg_content_pred))\n",
        "\n",
        "  avg_prediction = round((predicted_color_category + avg_content_pred) / 2)\n",
        "  print(\"Average prediction : \" + str(avg_prediction))\n",
        "\n",
        "  return (predicted_color_category, avg_content_pred, avg_prediction)"
      ],
      "metadata": {
        "id": "m-zzfjfXDPDO"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run all methods to train network and test it**"
      ],
      "metadata": {
        "id": "mDA4EHanmw6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive for reading in data\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Print categories for referencing\n",
        "\n",
        "print(\"\\nCategories : \" , categories_int)"
      ],
      "metadata": {
        "id": "GWr05tFaH5M8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5addba81-2416-4207-c2ba-eeab2f9fc608"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Categories :  {'frogs': 0, 'dogs': 1, 'cats': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set path variables according to what is shown in mounted google drive\n",
        "\n",
        "path_to_train_data = \"/content/drive/MyDrive/final_data/data\"\n",
        "path_to_test_data = \"/content/drive/MyDrive/final_data/testdata\"\n",
        "test_video_category = \"cats\"\n",
        "path_to_test_video = \"/content/drive/MyDrive/final_data/test_video/test_video.mp4\""
      ],
      "metadata": {
        "id": "sKDjWXsDLsaY"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use functions above to train the models and load data\n",
        "\n",
        "# Load data from training directory\n",
        "path_to_data = path_to_train_data\n",
        "video_data = loadData(path_to_data)\n",
        "\n",
        "categories = video_data[1]\n",
        "frame_data = video_data[0]\n",
        "\n",
        "# Modify frames into correct data style\n",
        "average_frames = get_frames_averaged(frame_data, categories)\n",
        "differentiated_frames = get_frames_difference(frame_data, categories)\n",
        "\n",
        "# Format the modified frames into dataset usuable by models\n",
        "frame_color_data = format_color_data(average_frames)\n",
        "frame_content_data = format_content_data(differentiated_frames)\n",
        "\n",
        "# Generate the network's models\n",
        "create_network_models()\n",
        "\n",
        "# Train the models with formatted data (this may take a while depending on the data loaded)\n",
        "train_color_model(frame_color_data[0], frame_color_data[1], 20)\n",
        "train_content_model(frame_content_data[0], frame_content_data[1], 20)"
      ],
      "metadata": {
        "id": "8vpKYvyNl8ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use functions above to test the models\n",
        "\n",
        "# Load data from test directory\n",
        "test_path_to_data = path_to_test_data\n",
        "test_video_data = loadData(test_path_to_data)\n",
        "\n",
        "test_frame_data = test_video_data[0]\n",
        "\n",
        "# Modify frames into correct data style\n",
        "test_average_frames = get_frames_averaged(test_frame_data, categories)\n",
        "test_differentiated_frames = get_frames_difference(test_frame_data, categories)\n",
        "\n",
        "# Format the modified frames into dataset usuable by models\n",
        "test_frame_color_data = format_color_data(test_average_frames)\n",
        "test_frame_content_data = format_content_data(test_differentiated_frames)\n",
        "\n",
        "# Evaluate models\n",
        "color_model.evaluate(test_frame_color_data[0], test_frame_color_data[1])\n",
        "content_model.evaluate(test_frame_content_data[0], test_frame_content_data[1])"
      ],
      "metadata": {
        "id": "FUiqnXZ9Aoa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data for testing a video\n",
        "\n",
        "test_video_frames = get_split_video_frames((get_video_from_path(path_to_test_video)), 10, test_video_category)\n",
        "\n",
        "average_frames_test = get_frames_averaged(test_video_frames, categories)\n",
        "differentiated_frames_test = get_frames_difference(test_video_frames, categories)\n",
        "\n",
        "frame_color_data_test = format_color_data(average_frames_test)\n",
        "frame_content_data_test = format_content_data(differentiated_frames_test)"
      ],
      "metadata": {
        "id": "HzvwK7kv3qm-"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print results of video prediction\n",
        "\n",
        "results = predict_video_type(frame_color_data_test, frame_content_data_test)\n",
        "\n",
        "print(\"Original Category : \" + test_video_category)\n",
        "print(\"Predicted Category : \" + int_categories[results[2]])"
      ],
      "metadata": {
        "id": "Fj77nAXh9h8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f01bf42-88c2-4dab-de43-6482648a7f0c"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Color prediction : 0\n",
            "Content prediction : 1\n",
            "Average prediction : 0\n",
            "Original Category : cats\n",
            "Predicted Category : frogs\n"
          ]
        }
      ]
    }
  ]
}